<link rel="stylesheet" href="assets/css/splendor.css">


<h1 id="sas-statistical-analysis-systems">SAS: statistical analysis systems</h1>



<h2 id="general-stuff">General stuff</h2>

<ul>
<li><strong>Comments</strong></li>
</ul>

<p><code>/* comment */</code></p>

<p><code>* comment statement;</code></p>



<h2 id="accessing-data">Accessing data</h2>



<h3 id="accessing-sas-libraries">Accessing SAS libraries</h3>

<ul>
<li><strong>libref</strong>: library reference name (shortcut to the physical location). There are three rules for valid librefs: <br>
<ul><li>A length of one to eight characters</li>
<li>Begin with a letter or underscore</li>
<li>The remaining characters are letters, numbers, or underscores</li>
<li>Valid variable names begin with a letter or underscore, and continue with letters, numbers, or underscores. The <strong>VALIDVARNAME</strong> system option specifies the rules for valid SAS variable names that can be created and processed during a SAS session:  <br>
<code>OPTIONS VALIDVARNAME=V7 (default) | UPCASE | ANY;</code></li></ul></li>
<li><strong>libref.data-set-name</strong>: data set reference two-level name</li>
<li><strong>data-set-name</strong>: when the data set belongs to a temporary library, you can optionally use a one-level name (SAS assumes that it is contained in the <strong>work</strong> library, which is the default)</li>
<li>The <strong>LIBNAME</strong> statement associates the <strong>libref</strong> with the physical location of the library/data for the current SAS session</li>
</ul>

<p><code>LIBNAME libref-name 'SAS-library-folder-path' &lt;options&gt;;</code></p>

<p><em>Example</em></p>

<p><code>%let path=/folders/myfolders/ecprg193;  <br>
libname orion "&amp;path";</code></p>

<ul>
<li>To erase the association between SAS and a custom library</li>
</ul>

<p><code>LIBNAME libref-name CLEAR;</code></p>

<ul>
<li>To check the <strong>contents of a library</strong> programatically</li>
</ul>

<p><code>PROC CONTENTS DATA=libref._ALL_; <br>
RUN;</code></p>

<ul>
<li>To hide the descriptors of all data sets in the library (it could generate a very long report) you can add the option <strong>nods</strong> (only compatible with the keybord <strong>_all_</strong>)</li>
</ul>

<p><code>PROC CONTENTS DATA=libref._ALL_ NODS; <br>
RUN;</code></p>

<ul>
<li>To access a data set you can use a <strong>proc print</strong> step</li>
</ul>

<p><code>PROC PRINT DATA=SAS-data-set; <br>
RUN;</code></p>



<h3 id="examining-sas-data-sets">Examining SAS data sets</h3>

<p>Parts of a library (SAS notation): <br>
- Table = <strong>data set</strong> <br>
- Column = <strong>variable</strong> <br>
- Row = <strong>observation</strong></p>

<p>The <strong>descriptor portion</strong> (PROC CONTENTS) contains information about the attributes of the data set (metadata), including the variable names. It is show in three tables: <br>
- Table 1: general information about the data set (name, creation date/time, etc.) <br>
- Table 2: operating environment information, file location, etc. <br>
- Table 3: alphabetic list of varibles in the data set and their attributes</p>

<p>The <strong>data portion</strong> (PROC PRINT) contains the data values, stored in variables (numeric/character) <br>
- Numeric values: right-aligned <br>
- Character values: left-aligned <br>
- <strong>Missing values</strong>: <strong><em>blank</em></strong> for character variables and <strong><em>period</em></strong> for numeric ones. To change this default behaviour use  <code>MISSING='new-character'</code> <br>
- Valid <strong>character values</strong>: letters, numbers, special characters and blanks <br>
- Valid <strong>numeric values</strong>: digits 0-9, minus sign, single decimal point, scientific notation (E) <br>
- Values length: for character variables 1 byte = 1 character, numeric variables have 8 bytes of storage by default (16-17 significant digits) <br>
- Other attributes: <strong>format</strong>, <strong>informat</strong>, <strong>label</strong></p>



<h2 id="producing-detailed-reports">Producing detailed reports</h2>



<h3 id="subsetting-report-data">Subsetting Report Data</h3>

<p><code>PROC PRINT DATA=SAS-data-set(OBS=3) NOOBS;  /* OBS=3 prints only 3 elements | NOOBS hides the 'Obs' */ <br>
    VAR variable1 variable2 variable3;      /* prints out only this variables in the report */ <br>
    SUM variable1 variable2;                /* adds an extra line at the end with the total */ <br>
    WHERE variable3&lt;1000;                   /* operators: &lt; &gt; &lt;= &gt;= = ^= in + - / * ** &amp; | ~ ^ ? */ <br>
    WHERE variable4 in ('Child','Elder');   /* only the last WHERE condition is applied */ <br>
    WHERE variable1=20 AND variable4 CONTAINS 'case-sensitive-substring';  /* CONTAINS = ? */ <br>
    ID variable1                            /* replaces the 'Obs' column by a selected variable values */ <br>
    BY variable3                            /* separate in different tables for different variable values (sort first) */ <br>
RUN;</code></p>

<p>Special <strong>WHERE operators</strong>: <br>
- <strong>BETWEEN x AND y</strong>: an inclusive range <br>
- <strong>WHERE SAME AND</strong>: augment a previous where expression (both applied) <br>
- <strong>IS NULL</strong>: a missing value <br>
- <strong>IS MISSING</strong>: a missing value <br>
- <strong>LIKE</strong>: matches a pattern (% = any number of characters, _ = one character). E.g.: ‘T_m%’ <br>
- The <strong>SOUNDS-LIKE (=*)</strong> operator selects observations that contain a spelling variation of a specified word or words. This operator uses the <em>Soundex</em> algorithm to compare the variable value and the operand.</p>

<p><strong>Note:</strong> To compare with a SAS date value you need to express is as a SAS date constant: <strong>‘DDMM&lt;\YY&gt;YY’D</strong></p>



<h3 id="sorting-and-grouping-report-data">Sorting and Grouping Report Data</h3>

<p><code>PROC SORT DATA=SAS-data-set <br>
    OUT=new-SAS-data-set NODUPKEY;                                           /* optional */ <br>
    DUPOUT=work.duplicates;                                                  /* optional */ <br>
    BY ASCENDING variable1-to-be-sorted DESCENDING variable2-to-be-sorted;   /* optional (ASCENDING is the default order)*/ <br>
RUN;</code></p>

<ul>
<li>The <strong>NODUPKEY</strong> option deletes observations with duplicate <strong>BY</strong> values</li>
<li><strong>DUPOUT</strong> writes duplicate observations to a separate output data set</li>
</ul>



<h3 id="enhancing-reports">Enhancing Reports</h3>

<p><code>TITLEline 'text'; <br>
FOOTNOTEline 'text';</code></p>

<p><code>TITLE1 'text1'; <br>
TITLE1 'text1_change';     /* Change title text and also cancels all footnotes with higher numbers */ <br>
TITLE;                     /* Cancel (erase) all titles */</code></p>

<ul>
<li>The <strong>lines</strong> specifies the line (1-10) on which the title/footnote will appear (line = 1 is the default value)</li>
<li>The title/footnote will remain until you <strong>change</strong> it, <strong>cancel</strong> it or you <strong>end your SAS session</strong></li>
</ul>

<hr>

<p>Assigning <strong>temporary labels</strong> to display in the report instead of the variable names:</p>

<p><code>PROC PRINT DATA=SAS-data-set LABEL;           /* you need to add the LABEL option to display the labels */  <br>
    LABEL variable1 = 'new variable1 name'  <br>
          variable2 = 'new variable2 name'; <br>
    LABEL variable3 = 'new variable3 name'; <br>
RUN;</code></p>

<ul>
<li>The <strong>LABEL</strong> lengths can go up to 256 characters long</li>
<li>You can specify several labels in one <strong>LABEL</strong> statement or use a separate <strong>LABEL</strong> statement for each variable</li>
</ul>

<p><code>PROC PRINT DATA=SAS-data-set SPLIT='*';           /* you no longer need to add the LABEL option, SPLIT does the same work */  <br>
    LABEL variable1 = 'new variable1*long name';   /* the variable name ocuppies 2 lines now */ <br>
RUN;</code></p>



<h2 id="formatting-data-values">Formatting data values</h2>



<h3 id="using-sas-formats">Using SAS formats</h3>

<p><code>PROC PRINT DATA=SAS-data-base; <br>
    FORMAT variable1 variable2 format; <br>
    FORMAT variable3 format3 variable4 format4; <br>
RUN;</code></p>

<p>Format definition: <strong>&lt;<span>$</span>&gt;<em>format</em>&lt;\w&gt;.&lt;\d&gt;</strong> <br>
- <strong>&lt;<span>$</span>&gt;</strong> = character format <br>
- <strong><em>format</em></strong> = format name <br>
- <strong>&lt;\w&gt;</strong> = total width (includes special characters, commas, decimal point and decimal places) <br>
- <strong>.</strong> = required syntax (dot) <br>
- <strong>&lt;\d&gt;</strong> = decimal places (numeric format)</p>

<p>SAS formats (<a href="http://support.sas.com/documentation/cdl/en/leforinforref/64790/HTML/default/viewer.htm#p0z62k899n6a7wn1r5in6q5253v1.htm">Dictionary of formats</a>): <br>
- <strong><span>$</span>w.</strong> = writes standard character data <br>
- <strong><span>$</span>UPCASE.</strong> = writes a string in uppercase <br>
- <strong><span>$</span>QUOTE.</strong> = writes a string in quotation marks  <br>
- <strong>w.d</strong> = writes standard numeric data <br>
- <strong>COMMAw.d</strong> = writes numeric values with a comma that separates every three digits and a period that separates the decimal fraction <br>
- <strong>DOLLARw.d</strong> = writes numeric values with a leading dollar sign, a comma that separates every three digits and a period that separates the decimal fraction <br>
- <strong>COMMAXw.d</strong> = writes numeric values with a period that separates every three digits and a coma that separates the decimal fraction <br>
- <strong>EUROXw.d</strong> = writes numeric values with a leading euro symbol, a period that separates every three digits and a comma that separates the decimal fraction</p>

<p>SAS date values: <strong>MMDDYY&lt;\w&gt;.</strong> / <strong>DDMMYY&lt;\w&gt;.</strong> / <strong>MONYY&lt;\w&gt;.</strong> / <strong>DATE&lt;\w&gt;.</strong> / <strong>WEEKDATE.</strong> <br>
- w = 6: only date numbers <br>
- w = 8: date numbers with <strong>/</strong> separators (just the last 2 digits of year) <br>
- w = 10: date numbers with <strong>/</strong> separators (full 4-digit year)</p>

<p><strong>Note:</strong> dates before 01/01/1960 (0 value) will appear as negative numbers</p>



<h3 id="creating-and-applying-user-defined-formats">Creating and applying user-defined formats</h3>

<p><code>PROC FORMAT; <br>
    VALUE &lt;$&gt;format-name value-or-range1='formatted-value1' <br>
                      value-or-range2='formatted-value2'; <br>
RUN;</code></p>

<p><code>PROC PRINT DATA=SAS-data-set; <br>
    FORMAT variable1 &lt;$&gt;format-name.; <br>
RUN;</code></p>

<ul>
<li>A format name can have a maximum of <strong>32 characters</strong></li>
<li>The name of a format that applies to <strong>character values</strong> must begin with a <strong>dollar sign</strong> followed by a letter or underscore</li>
<li>The name of a format that applies to <strong>numeric values</strong> must begin with a letter or underscore</li>
<li>A format name cannot end in a number</li>
<li>All remaining characters can be letters, underscores or numbers</li>
<li>A user defined format name cannot be the name of a SAS format</li>
</ul>

<p>Each <strong>value-range set</strong> has three parts: <br>
- <strong>value-or-range</strong>: specifies one or more values to be formatted (it can be a value, a range or a list of values) <br>
- <strong>=</strong>: equal sign <br>
- <strong>formatted-value</strong>: the formatted value you want to display instead of the stored value/s (it is allways a character string no matter wheter the format applies to character values or numeric values)</p>

<p><code>PROC FORMAT LIBRARY = my-format-library;   /* To save the custom formats */ <br>
    VALUE string 'A'-'H'='First' <br>
                 'I','J','K'='Middle' <br>
                  OTHER = 'End';           /* Non-specified values */ <br>
    VALUE tiers low-&lt;50000='Tier1'         /* 50000 not included */ <br>
                50000-&lt;100000='Tier2'      /* 100000 not included */ <br>
                100000-high='Tier3' <br>
                .='Missing value'; <br>
RUN;</code></p>

<p><strong>Note1:</strong> if you omit the <strong>LIBRARY</strong> option, then formats and informats are stored in the <strong>work.formats</strong> catalog</p>

<p><strong>Note2:</strong> if you do not includ the keyword <strong>OTHER</strong>, then SAS applies the format only to values that match the value-range sets that you specify and the rest of values are displayed as they are stored in the data set</p>

<p><strong>Note3:</strong> you can only use the <strong>&lt;</strong> symbol to define a non-inclusive range.</p>

<p><code>OPTIONS FMTSEARCH = (libref1 libref2... librefn)</code></p>

<ul>
<li>The <strong>FMTSEARCH</strong> system option controls the order in which format catalogs are searched until the desired member is found.</li>
<li>The <strong>WORK.FORMATS</strong> catalog is always searched first, unless it appears in the <strong>FMTSEARCH</strong> list. </li>
</ul>



<h2 id="reading-sas-data-sets">Reading SAS data sets</h2>

<p>To create a new data set that is a subset of a previous data set:</p>

<p><code>DATA output-SAS-data-set; <br>
    SET input-SAS-data-set; <br>
    WHERE where-expression; <br>
    variable_name = expression;     /* new variable creation */ <br>
RUN;</code></p>

<p><strong>Note1:</strong> if a missing value is involved in an arithmetic calculation the result will be a missing value too</p>

<p><strong>Note2:</strong> new variables being created in the DATA step and not contained in the original data set cannot be used in a WHERE statement</p>



<h3 id="customizing-a-sas-data-set">Customizing a SAS data set</h3>

<p>How to select a subset of the variables/observations of the original data set:</p>

<p><code>DATA output-SAS-data-set; <br>
    SET input-SAS-data-set; <br>
    DROP variable-list;        /* original variables to exclude */ <br>
    KEEP variable-list;        /* original variables to include + new variables */ <br>
RUN;</code></p>

<p>How SAS processes the <strong>DATA</strong> step:</p>

<p><strong>Compilation phase</strong> <br>
- SAS scan each DATA step statement for syntax errors and converts the program into machine code if everything’s alright.  <br>
- SAS also creates the program data vector (<strong>PDV</strong>) in memory to hold the current observation. <br>
 - <strong>_N_</strong>: iteration number of the DATA step <br>
 - <strong>_ERROR_</strong>: its value is 0 is there are no errors (1 if there are some) <br>
- SAS creates the descriptor portion of the new data set (takes the original one, adds the new variables and flags the variables to be dropped). </p>

<p><strong>Execution phase</strong> <br>
- SAS initializes the PDV to missing <br>
- SAS reads and processes the observations from the input data set  <br>
- SAS creates observations in the data portion of the output data set (an implicit output/implicit return loop over all the observations that continues until EOF)</p>

<hr>

<p>Subsetting <strong>IF</strong> statement: </p>

<p><code>DATA output-SAS-data-set; <br>
    SET input-SAS-data-set; <br>
    IF expression; <br>
RUN;</code></p>

<ul>
<li>When the expression is false, SAS excludes the observation from the output data set and continues processing</li>
<li>While original values can be managed with a <strong>WHERE</strong> statement as well as an <strong>IF</strong> statement, for <strong>new variable</strong> conditionals only <strong>IF</strong> can be used</li>
<li>You should subset as early as possible in your program for more efficient processing (a <strong>WHERE</strong> before an <strong>IF</strong> can make the processing more efficient).</li>
<li>In a <strong>PROC</strong> step <strong>IF</strong> statements are <strong>NOT allowed</strong></li>
</ul>

<hr>

<p>Subsetting <strong>IF-THEN/DELETE</strong> statement: </p>

<p><code>DATA output-SAS-data-set; <br>
    SET input-SAS-data-set; <br>
    IF expression1 or expression2 then delete; <br>
RUN;</code></p>

<ul>
<li>The <strong>IF-THEN/DELETE</strong> statement eliminates the observations where the <strong>conditions are not met</strong> (on the contrary of what the <strong>IF</strong> does)</li>
<li>The <strong>DELETE</strong> statement stops processing the current observation. It is often used in a THEN clause of an IF-THEN statement or as part of a conditionally executed DO group.</li>
</ul>

<hr>

<p>Addition of several variables: <code>Total=sum(var1, var2, var3)</code></p>

<p>Count of nonmissing values: <code>Nonmissing=n(var1, var2, var3)</code></p>



<h3 id="adding-permanent-attributes">Adding permanent attributes</h3>

<p><strong><em>Permanent variable labels</em></strong></p>

<p><code>DATA output-SAS-data-set; <br>
    SET input-SAS-data-set; <br>
    LABEL variable1='label1' <br>
          variable2='label2'; <br>
RUN;</code></p>

<p><code>PROC PRINT DATA=output-SAS-data-set label; <br>
RUN;</code></p>

<ul>
<li>If you use the <strong>LABEL</strong> statement in the <strong>PROC</strong> step the labels are <strong>temporary</strong> while if you use it in the <strong>DATA</strong> step, SAS <strong>permanently</strong> associates the labels to the variables</li>
<li>Labels and formats that you specify in <strong>PROC</strong> steps override the permanent labels in the current step. However, the permanent labels are not changed.</li>
</ul>

<p><strong><em>Permanent variable formats</em></strong></p>

<p><code>DATA output-SAS-data-set; <br>
    SET input-SAS-data-set; <br>
    FORMAT variable1 format1 <br>
           variable2 format2; <br>
RUN;</code></p>



<h2 id="reading-spreadsheet-and-database-data">Reading spreadsheet and database data</h2>



<h3 id="reading-spreadsheet-data">Reading spreadsheet data</h3>

<p>To determine the SAS products that are included in your SAS license, you can run the following PROC SETINIT step:</p>

<p><code>PROC SETINIT; <br>
RUN;</code></p>

<hr>

<p>SAS/ACCESS LIBNAME statement (read/write/update data):</p>

<p><code>LIBNAME libref &lt;engine&gt; &lt;PATH=&gt;"workbook-name" &lt;options&gt;;</code></p>

<p>E.g.:<br>
<strong>Default engine:</strong> <code>LIBNAME orionx excel "&amp;path/sales.xls"</code><br>
<strong>PC Files server engine:</strong> <code>LIBNAME orionx pcfiles PATH="&amp;path/sales.xls"</code><br></p>

<ul>
<li><strong>&lt;\engine&gt;</strong>: excel (if both SAS and Office are 32/64 bits), pcfiles (if the value is different)</li>
<li>The icon of the library will be different (a globe) indicating that the data is outside SAS</li>
<li>The members whose name ends with a <strong><span>$</span></strong> are the <strong>spreadsheets</strong> while the others are named <strong>ranges</strong>. In case it has the <strong><span>$</span></strong>, you need to refer to that Excel worksheet in a special way to account for that special character (SAS name literal): <code>libref.'worksheetname\$'n</code></li>
<li>You can use the <strong><code>VALIDVARNAME = v7</code></strong> option in SAS Enterprise Guide to cause it to behave the same as in the SAS window environment</li>
<li>Is important to disassociate the library: the workbook cannot be opened in Excel meanwhile (SAS puts a lock on the Excel file when the libref is assigned): <strong><code>LIBNAME libref CLEAR;</code></strong></li>
</ul>

<hr>

<p>Import the xls data:</p>

<p><code>PROC IMPORT DATAFILE="/folders/myfolders/reading_test.xlsx" <br>
            OUT=work.myexcel  <br>
            DBMS=xlsx  <br>
            REPLACE; <br>
RUN;</code></p>



<h3 id="reading-database-data">Reading database data</h3>

<p><code>LIBNAME libref engine &lt;SAS/ACCESS options&gt;;</code></p>

<ul>
<li><strong>engine</strong>: oracle or BD2</li>
<li><strong>SAS/ACCESS options</strong>: USER, PASSWORD/PW, PATH (specifies the Oracle driver, node and database), SCHEMA (enables you to read database objects such as tables and views)</li>
</ul>



<h2 id="reading-raw-data-files">Reading raw data files</h2>



<h3 id="introduction-to-reading-raw-data-files">Introduction to reading raw data files</h3>

<ul>
<li><strong>Raw data files</strong> are not software specific</li>
<li>A <strong>delimited raw data file</strong> is an external text file in which the values are separated by spaces or other special characters.</li>
<li>A <strong>list input</strong> will be used to work with delimited raw data files that contain standard and/or nonstandard data</li>
<li><strong>Standard data</strong> is data that SAS can read without any special instructions</li>
<li><strong>Nonstandard data</strong> includes values like dates or numeric values that include special characters like dollar signs (extra instructions needed)</li>
</ul>



<h3 id="reading-standard-delimited-data">Reading standard delimited data</h3>

<p><code>DATA output-SAS-data-set-name; <br>
    LENGTH variable(s) &lt;$&gt; length; <br>
    INFILE 'raw-data-file-name' DLM='delimiter'; <br>
    INPUT variable1 &lt;$&gt; variable2 &lt;$&gt; ... variableN &lt;$&gt;;    /* $ = character variables */ <br>
RUN;</code></p>

<p><strong>E.g.:</strong><br>
<code>DATA work.sales1; <br>
    LENGTH First_Name Last_Name $ 12 Gender $ 1; <br>
    INFILE '&amp;path/sales.csv' DLM=','; <br>
    INPUT Employee_ID Gender $ Salary $ Job_Title $ Country $;  <br>
RUN;</code></p>

<ul>
<li>With <strong>list input</strong>, the default length for all variables is 8 bytes</li>
<li>SAS uses an <strong>input buffer</strong> only if the input data is a raw data file</li>
<li>The variable names will appear in the report as stated in the <strong>LENGTH</strong> statement (watch out the uppercase/lowercase)</li>
<li>The <strong>LENGTH</strong> statement must precede the <strong>INPUT</strong> statement in order to correctly set the length of the variable</li>
<li>The variables not specified in the <strong>LENGTH</strong> statement will appear at the end of the table. If you want to keep the original order you should include all variables even if you want them to have the defaul length (8)</li>
</ul>



<h3 id="reading-nonstandard-delimited-data">Reading nonstandard delimited data</h3>

<p>You can use a <strong>modified list input</strong> to read all of the fields from a raw data file (including nonstandard variables)</p>

<ul>
<li>Informats are similar to formats except that <strong>formats</strong> provide instruction on how to <strong>write</strong> a value while <strong>informats</strong> provide instruction on how to <strong>read</strong> a value</li>
<li>The <strong>colon format modifier (:)</strong> causes SAS to read up to the delimiter</li>
</ul>

<p><code>INPUT variable &lt;$&gt; variable &lt;:informat&gt;;</code></p>

<p><strong>E.g.:</strong><br>
<code>:date. <br>
:mmddyy.</code></p>

<ul>
<li><strong>COMMA./DOLLAR.</strong>: reads nonstandard numeric data and removes embedded commas, blanks, dollar sign, percent signs and dashes</li>
<li><strong>COMMAX./DOLLARX.</strong>: reads nonstandard numeric data and removes embedded non-numeric characters; reverses the roles of the decima point and the comma</li>
<li><strong>EUROX.</strong>: reads nonstandard numeric data and removes embedded non-numeric characters in European currency</li>
<li><strong><span>$</span>CHAR.</strong>: reads character values and preserves leading blanks</li>
<li><strong><span>$</span>UPCASE.</strong>: reads character values and converts them to uppercase</li>
</ul>

<hr>

<ul>
<li>You cannot use a <strong>WHERE</strong> statement when the input data is a raw data file instead of a SAS data set</li>
</ul>

<hr>

<p><code>DATA (...); <br>
    INFILE DATALINES DLM=',';   /* only if datalines are delimited */ <br>
    INPUT (...); <br>
    DATALINES; <br>
    &lt;instream data&gt; <br>
    ;</code></p>

<ul>
<li>The null statement (<strong>;</strong>) indicates the end of the input data</li>
<li>You precede the instream data with the <em>DATALINES</em> statement and follow it with a null statement</li>
<li>The instream data should be the <strong>last part of the DATA step</strong> except for a null statement</li>
</ul>

<p><strong>E.g.:</strong><br></p>

<p><code>data work.managers; <br>
   infile datalines dlm='/'; <br>
   input ID First :$12. Last :$12. Gender $ Salary :comma.  <br>
            Title :$25. HireDate :date.; <br>
   datalines; <br>
120102/Tom/Zhou/M/108,255/Sales Manager/01Jun1993 <br>
120103/Wilson/Dawes/M/87,975/Sales Manager/01Jan1978 <br>
120261/Harry/Highpoint/M/243,190/Chief Sales Officer/01Aug1991 <br>
121143/Louis/Favaron/M/95,090/Senior Sales Manager/01Jul2001 <br>
121144/Renee/Capachietti/F/83,505/Sales Manager/01Nov1995 <br>
121145/Dennis/Lansberry/M/84,260/Sales Manager/01Apr1980 <br>
;</code></p>

<p><code>title 'Orion Star Management Team'; <br>
proc print data=work.managers noobs; <br>
   format HireDate mmddyy10.; <br>
run; <br>
title;</code></p>



<h3 id="validating-data">Validating data</h3>

<p>When SAS encounters a data error, it prints messages and a ruler in the log and assigns a missing value to the affected variable. Then SAS continues processing.</p>

<hr>

<p><strong><em>Missing values between delimiters (consecutive delimiters)</em></strong></p>

<p><code>INFILE 'raw-data-file-name' &lt;DLM=&gt; DSD;</code></p>

<p>The <strong>DSD</strong> option sets the default delimiter to a comma, treats consecutive delimiters as missing values and enables SAS to read values with embedded delimiters if the value is surrounded by quotation marks</p>

<hr>

<p><strong><em>Missing values at the end of a line</em></strong></p>

<p><code>INFILE 'raw-data-file-name' MISSOVER;</code></p>

<p>With the <strong>MISSOVER</strong> option, if SAS reaches the end of a record without finding values for all fields, variables without values are set to <em>missing</em>.</p>



<h2 id="manipulating-data">Manipulating Data</h2>



<h3 id="using-sas-functions">Using SAS functions</h3>

<p><strong><em>SUM function</em></strong></p>

<p><code>SUM(argument1, argument2, ...)</code> <br>
- The arguments must be numeric values <br>
- The <strong>SUM</strong> function ignores missing values, so if an argument has a missing value, the result of the SUM function is the sum of the nonmissing values</p>



<h2 id="if-you-add-two-values-by-if-one-of-them-is-missing-the-result-will-be-a-missing-value-which-makes-the-sum-function-a-better-choice">- If you add two values by <strong>+</strong>, if one of them is missing, the result will be a missing value which makes the <strong>SUM</strong> function a better choice</h2>

<p><strong><em>DATE funtion</em></strong></p>

<p><code>YEAR(SAS-date) <br>
QTR(SAS-date) <br>
MONTH(SAS-date) <br>
DAY(SAS-date) <br>
WEEKDAY(SAS-date) <br>
TODAY()                /* Obtain the current date and convert to SAS-date (no argument) */ <br>
DATE()                 /* Obtain the current date and convert to SAS-date (no argument) */ <br>
MDY(month, day, year)</code></p>

<ul>
<li>The arguments must be numeric values (except from <strong>TODAY()</strong> and <strong>DATE()</strong> functions)</li>
<li>You can subtract dates: <code>Agein2012=(Bday2012-Birth_Date)/365.25;</code></li>
</ul>

<hr>

<p><strong><em>Concatenation function</em></strong></p>

<p><code>CATX(' ', First_Name, Last_Name)</code></p>

<p>The <strong>CATX</strong> function removes leading and trailing blanks, inserts delimiters, and returns a concatenated character string. In the code, you first specify a character string that is used as a delimiter between concatenated items.</p>

<hr>

<p><strong><em>Time interval function</em></strong></p>

<p><code>INTCK('year', Hire_Date, '01JAN2012'd)</code></p>

<p>The <strong>INTCK</strong> function returns the number of interval boundaries of a given kind that lie between the two dates, times, or datetime values. In the code, you first specify the interval value.</p>

<hr>

<p><strong><em>What happens if you use a variable to describe a new one that you are gonna DROP in that same DATA statement?</em></strong></p>

<p>The <strong>DROP</strong> statement is a compile-time-only statement. SAS sets a drop flag for the dropped variables, but the variables are in the PDV and, therefore, are available for processing.</p>



<h3 id="conditional-processing">Conditional processing</h3>

<p><strong><em>IF-THEN-ELSE conditional structures</em></strong></p>

<p><code>IF expression THEN statement; <br>
ELSE IF expression THEN statement; <br>
ELSE statement;</code></p>

<p>In the conditional expressions involving strings watch out for possible mixed case values where the condition may not be met: <code>Country = upcase(Country);</code> to avoid problems</p>

<hr>

<p><strong><em>Executing multiple statements in an IF-THEN-ELSE statement</em></strong></p>

<p><code>IF expression THEN <br>
    DO; <br>
        executable statements; <br>
    END; <br>
ELSE IF expression THEN <br>
    DO; <br>
        executable statements; <br>
    END;</code></p>



<hr>

<p>In the <strong>DATA</strong> step, the first reference to a variable determines its length. The first reference to a new variable can be in a <strong>LENGTH</strong> statement, an <strong>assignment</strong> statement, or <strong>another</strong> statement such as an INPUT statement. After a variable is created in the PDV, the length of the variable’s first value doesn’t matter. </p>

<p>To avoid truncation in a variable defined inside a conditional structure you can:</p>

<ul>
<li>Define the longer string as the first condition</li>
<li>Add some blanks at the end of shorter strings to fit the longer one</li>
<li>Define the length explicitly before any other reference to the variable</li>
</ul>

<hr>

<p><strong><em>SELECT group</em></strong></p>

<p><code>SELECT(Gender); <br>
      WHEN('F') DO; <br>
         Gift1='Scarf'; <br>
         Gift2='Pedometer'; <br>
      END; <br>
      WHEN('M') DO; <br>
         Gift1='Gloves'; <br>
         Gift2='Money Clip'; <br>
      END; <br>
      OTHERWISE DO; <br>
         Gift1='Coffee'; <br>
         Gift2='Calendar'; <br>
      END; <br>
END;</code></p>

<ul>
<li>The <strong>SELECT</strong> statement executes one of several statements or groups of statements</li>
<li>The <strong>SELECT</strong> statement begins a SELECT group. They contain <strong>WHEN</strong> statements that identify SAS statements that are executed when a particular condition is true</li>
<li>Use at least one <strong>WHEN</strong> statement in a SELECT group</li>
<li>An optional <strong>OTHERWISE</strong> statement specifies a statement to be executed if no <strong>WHEN</strong> condition is met</li>
<li>An <strong>END</strong> statement ends a <strong>SELECT</strong> group</li>
</ul>



<h2 id="combining-sas-data-sets">Combining SAS Data Sets</h2>



<h3 id="concatenating-data-sets">Concatenating Data Sets</h3>

<p><strong><em>Combine files vertically by concatenating</em></strong></p>

<p><code>DATA SAS-data-set; <br>
    SET SAS-data-set1 SAS-data-set2 ...; <br>
RUN;</code></p>

<p><strong><em>Combine two different variables that are actually the same one</em></strong></p>

<p><code>DATA SAS-data-set; <br>
    SET SAS-data-set1 (RENAME=(old-name1 = new-name1 old-name2 = new-name2)) SAS-data-set2 ...; <br>
RUN;</code></p>

<ul>
<li>The name change affects the PDV and the output data set, but has no effect on the input data set</li>
<li>The <strong>variable attributes</strong> are assigned from the <strong>first data set</strong> in the SET statement</li>
<li>You will get an <strong>error</strong> in the DATA step if a variable is defined with <strong>different data types</strong> in the files that you are trying to concatenate</li>
</ul>



<h3 id="merging-sas-data-sets-one-to-one">Merging SAS Data Sets One-to-One</h3>

<p><strong><em>Combine files horizontally by merging</em></strong></p>

<ul>
<li>The <strong>match-merging</strong> is a process based on the values of common variables</li>
<li>Data sets are merged in the order that they appear in the MERGE statement</li>
<li>You may need to <strong>SORT</strong> the files by the <strong>BY-variable(s)</strong> before merging the files</li>
</ul>

<p><code>DATA SAS-data-set; <br>
    MERGE SAS-data-set1 (RENAME=(old-name1 = new-name1 ...)) SAS-data-set2 ...; <br>
    BY &lt;DESCENDING&gt; BY-variable(s); <br>
    &lt;additional SAS statements&gt; <br>
RUN;</code></p>

<ul>
<li>In a <strong>one-to-one</strong> relationship, a single observastion in one data set is related to one, and only one, observation in another data set based on the values of one or more common variables</li>
<li>In a <strong>one-to-many</strong> relationship, a single observation in one data set is related to one or more observations in another data set</li>
<li>In a <strong>many-to-one</strong> relationship, multiple observations in one data set are related to one observation in another data set</li>
<li>In a <strong>many-to-many</strong> relationship, multiple observations in one data set are related to multiple observations in another data set</li>
<li>Sometimes the data sets have <strong>non-matches</strong>: at least one observation in one of the data sets is unrelated to any observation in another data set based on the values of one or more common variables</li>
</ul>



<h3 id="merging-sas-data-sets-one-to-many">Merging SAS Data Sets One-to-Many</h3>

<p><code>DATA SAS-data-set; <br>
    MERGE SAS-data-set1 SAS-data-set2 ...; <br>
    BY &lt;DESCENDING&gt; BY-variable(s); <br>
    &lt;additional SAS statements&gt; <br>
RUN;</code></p>

<p><em>In a <strong>one-to-many merge</strong>, does it matter which data set is listed first in the MERGE statement?</em></p>

<p>When you reverse the order of the data sets in the MERGE statement, the results are the same, but the order of the variables is different. SAS performs a <strong>many-to-one merge</strong>.</p>

<hr>

<p><strong>MERGENOBY</strong> (= NOWARN (default) | WARN | ERROR) controls whether a message is issued when MERGE processing occurs without an associated BY statement</p>

<ul>
<li>Performing a merge without a BY statement merges the observations based on their positions</li>
<li>This is almost never done intentionally and can lead to unexpected results</li>
</ul>



<h3 id="merging-sas-data-sets-that-have-non-matches">Merging SAS Data Sets that Have Non-Matches</h3>

<p><code>DATA SAS-data-set; <br>
    MERGE SAS-data-set1 SAS-data-set2 ...; <br>
    BY &lt;DESCENDING&gt; BY-variable(s); <br>
    &lt;additional SAS statements&gt; <br>
RUN;</code></p>

<ul>
<li>After the merging, the output data set contains <strong>both matches and non-matches</strong></li>
<li>You want the new data set to contain only the observations that match across the input data sets, and not those ones that are missing in one of the data sets that you are merging</li>
</ul>

<p><code>DATA SAS-data-set; <br>
    MERGE SAS-data-set1 (IN=variable1)  <br>
          SAS-data-set2 (IN=variable2) ...; <br>
    BY &lt;DESCENDING&gt; BY-variable(s); <br>
    &lt;additional SAS statements&gt; <br>
RUN;</code></p>

<ul>
<li>When you spefify the <strong>IN</strong> option after an input data set in the MERGE statement, SAS creates a <strong>temporary numeric variable</strong> that indicates whether the data set contributed data to the current observation (0 = it did not contribute to the current observation, 1 = it did contribute)</li>
<li>These variables are only available <strong>during execution</strong></li>
</ul>

<p><code>DATA SAS-data-set; <br>
    MERGE SAS-data-set1 (IN=variable1)  <br>
          SAS-data-set2 (IN=variable2) ...; <br>
    BY &lt;DESCENDING&gt; BY-variable(s); <br>
    IF variable1 = 1 and variable2 = 1;     /* write only matches */ <br>
    &lt;additional SAS statements&gt; <br>
RUN;</code></p>

<ul>
<li><strong><em>Matches</em></strong></li>
</ul>

<p><code>IF variable1 = 1 and variable2 = 1  <br>
IF variable1 and variable2</code> <br>
- <strong><em>Non-matches from either data set</em></strong></p>

<p><code>IF variable1 = 0 or not variable2 = 0 <br>
IF not variable1 or not variable2</code></p>

<p><strong><em>E.g.:</em></strong><br>
<code>DATA SAS-new-data-set1 SAS-new-data-set2; <br>
    MERGE SAS-data-set1 (in=var1) SAS-data-set2 (in=var2); <br>
    BY BY-variable(s); <br>
    IF var2 THEN OUTPUT SAS-new-data-set1; <br>
    ELSE IF var1 and not var2 THEN OUTPUT SAS-new-data-set2; <br>
    KEEP variable1 variable2 variable5 variable8; <br>
run;</code></p>



<h2 id="creating-summary-reports">Creating Summary Reports</h2>



<h3 id="using-proc-freq-to-create-summary-reports">Using PROC FREQ to Create Summary Reports</h3>

<ul>
<li>When you’re summarizing data, there’s no need to show a frequency distribution for variables that have a large number of distinct values</li>
<li>Frequency distributions work best with variables whose values meet two criteria: variable with <strong>categorical values</strong> and values are <strong>best summarized by counts instead of averages</strong></li>
<li>Variables that have continuous numerical values, such as dollar amounts and dates, will need to be <strong>grouped into categories</strong> by <strong>applying formats</strong> inside the PROC FREQ step (substitute an specific range of those values by a tag)</li>
</ul>

<p><code>PROC FREQ DATA=SAS-data-set &lt;option(s)&gt;; <br>
    TABLES variable(s) &lt;loption(s)&gt;; <br>
    &lt;additional statements&gt; <br>
RUN;</code></p>

<ul>
<li><strong>PROC FREQ</strong> produces frequency tables that report the distribution of any or all variable values in a SAS data set</li>
<li>In the <strong>TABLE</strong> statement you specify the frequency tables to produce </li>
<li>To create <strong>one-way</strong> frequency tables you specify one or more variable names separated by space</li>
<li><strong>WATCH OUT</strong>: if you omit the <strong>TABLE</strong> statement, SAS produces a one-way table for every variable in the data set</li>
<li>The <strong>PROC FREQ</strong> step automatically displays output in a report, so you don’t need to add a PROC PRINT step </li>
<li>Each unique variable’s value displayed in the 1<sup>st</sup> column of the output is called a <strong>level of the variable</strong></li>
</ul>

<hr>

<p><code>PROC FREQ DATA=SAS-data-set &lt;option(s)&gt;; <br>
    TABLES variable/NOCUM NOPERCENT; <br>
    &lt;additional statements&gt; <br>
RUN;</code></p>

<ul>
<li><strong>NOCUM</strong> option supresses the display of  the cummulative frequency and cummulative percent values </li>
<li><strong>NOPERCENT</strong> option supresses the display of all percentages</li>
</ul>

<hr>

<p><code>PROC SORT DATA=SAS-data-set <br>
    OUT=SAS-data-set-sorted; <br>
    BY variable_sorted; <br>
RUN;</code></p>

<p><code>PROC FREQ DATA=SAS-data-set-sorted; <br>
    TABLES variable-freq; <br>
    BY variable_sorted; <br>
RUN;</code></p>

<ul>
<li>Whenever you use the <strong>BY</strong> statement, the data set must be sorted by the variable named in the statement</li>
<li>Using this we will get a frequency table on <strong><code>variable_freq</code></strong> for each value of <strong><code>variable_sorted</code></strong></li>
</ul>

<hr>

<p><strong><em>Crosstabulation tables</em></strong></p>

<ul>
<li>Sometimes it is useful to view a single table with statistics for each distintic combination of values of the selected variables</li>
<li>The simplest crosstabulation table is a <strong>two-way table</strong></li>
</ul>

<p><code>PROC FREQ DATA=SAS-data-set; <br>
    TABLES variable1 * variable2 / NOFREQ NOPERCENT NOROW NOCOL; <br>
RUN;</code></p>

<p><code>variable1 = table rows <br>
variable2 = table columns</code></p>

<p>Information contained in crosstabulation tables (legend): <br>
- <strong>Frequency</strong>: indicates the number of observations with the unique combination of values represented in that cell <br>
- <strong>Percent</strong>: indicates the cell’s percentage of the total frequency <br>
- <strong>Row Pct</strong>: cell’s percentage of the total frequency for its row <br>
- <strong>Col Pct</strong>: cell’s percentage of the total frequency for its column  <br>
<br><br>
- <strong>LIST</strong> option format: the first two columns specify each possible combination of the two variables; it displays the same statistics as the default <strong>one-way frequency</strong> table <br>
- <strong>CROSSLIST</strong> option format: it displays the same statistics as the default <strong>crosstabulation</strong> table</p>

<hr>

<p>The <strong>FORMAT=</strong> option allows you to format the frequency value (to any SAS numeric format or a user-defined numeric format while its length is not more than 24) and to change the width of the column (e.g. to allow variable labels to fit in one line). </p>

<p><code>PROC FREQ DATA=SAS-data-set; <br>
    TABLES variable1 * variable2 / <br>
    FORMAT = &lt;w&gt;.; <br>
    FORMAT variable1 $format-name.; <br>
RUN;</code></p>

<p>The <strong>FORMAT=</strong> option applies only to crosstabulation tables displayed in the default format. It doesn’t apply to crosstabulation tables produced with the <strong>LIST</strong>/<strong>CROSSLIST</strong> option</p>



<h3 id="using-proc-freq-for-data-validation">Using PROC FREQ for Data Validation</h3>

<p>You can use a <strong>PROC FREQ</strong> step with the <strong>TABLES</strong> statement to detect invalud numeric and character data by looking at distinct values. The <strong>FREQ</strong> procedure <strong>lists all discrete values</strong> for a variable and <strong>reports its missing values</strong>.</p>

<p><code>PROC FREQ DATA=SAS-data-set &lt;ORDER=FREQ&gt;; <br>
    TABLES variable; <br>
RUN;</code></p>

<ul>
<li>You can check for non-expected variable’s values</li>
<li>You can check for missing values</li>
<li>You can find duplicated values</li>
</ul>

<hr>

<p>The table showing the <strong>Number of Variable Levels</strong> can indicate whether a variable contains duplicate/missing/non-expected values:</p>

<p><code>PROC FREQ DATA=SAS-data-set NLEVELS; <br>
    TABLES variable / NOPRINT; <br>
RUN;</code></p>

<hr>

<p>You can use a <strong>WHERE</strong> statement to print out only the invalid values to be checked:</p>

<p><code>PROC PRINT DATA=SAS-data-set; <br>
    WHERE gender NOT IN ('F','M') OR <br>
          job_title IS NULL OR <br>
          salary NOT BETWEEN 24000 AND 500000 OR <br>
          employee IS MISSING; <br>
RUN;</code></p>

<hr>

<p>You can output the tables to a new data set instead of displaying it:</p>

<p><code>PROC FREQ DATA=SAS-data-set NOPRINT; <br>
   TABLE variable / OUT=SAS-new-data-set; <br>
run;</code></p>



<h3 id="using-the-means-and-univariate-procedures">Using the MEANS and UNIVARIATE Procedures</h3>

<p><strong>PROC MEANS</strong> produces summary reports with descriptive statistics and you can create statistics for groups of observations</p>

<ul>
<li>It automatically displays output in a report and you can also save the output in a SAS data set</li>
<li>It reports the <strong>number of nonmissing values</strong> of the analysis variable (N), and the <strong>mean</strong>, the <strong>standard deviation</strong> and <strong>minimum/maximum values</strong> of every numeric variable in the data set</li>
<li>The variables in the <strong>CLASS</strong> statement are called <strong>classification variables</strong> or <strong>class variables</strong> (they typically have few discrete values)</li>
<li>Each combination of class variable values is called a <strong>class level</strong></li>
<li>The data set <strong>doesn’t need to be sorted</strong> or indexed by the class variables</li>
<li><strong>N Obs</strong> reports the number of observations with each unique combination of class variables, whether or not there are missing values (if these <strong>N Obs</strong> are identical to <strong>N</strong>, there are no missing values in you data set)</li>
</ul>

<p><code>PROC MEANS DATA=SAS-data-set &lt;statistic(s)&gt;; <br>
    VAR analysis-variable(s); <br>
    CLASS classification-variable(s); <br>
RUN;</code></p>

<p>To write the report in a new data set (including total addition):</p>

<p><code>PROC MEANS DATA=SAS-data-set NOPRINT NWAY; <br>
    OUTPUT OUT=SAS-new-data-set SUM=addition-new-variable; <br>
    VAR analysis-variable(s); <br>
    CLASS classification-variable(s); <br>
RUN;</code></p>

<p>Format options:  <br>
* <code>MAXDEC=number</code> (default format = BESTw.) <code>NONOBS</code> <br>
* <code>FW=number</code>: specifies that the field width for all columns is <em>number</em> <br>
* <code>PRINTALLTYPES</code>: displays statistics for all requested combination of class variables</p>

<p><img src="descriptive_statistics.png" alt="alt text" title="Descriptive statistics"> <br>
<img src="quantile_statistics.png" alt="alt text" title="Quantile statistics"></p>

<hr>

<p><strong>*Alternative procedure to validate data: *PROC MEANS</strong></p>

<ul>
<li>The <strong>MIN</strong>/<strong>MAX</strong> values can be useful to check if the data is within a range</li>
<li><strong>NMISS</strong> option displays the number of observations with missing values</li>
</ul>

<hr>

<p><strong>*Alternative procedure to validate data: *PROC UNIVARIATE</strong></p>

<p><strong>PROC UNIVARIATE</strong> is a procedure that is useful for detecting data outliers that also produces summary reports of <strong>descriptive statistics</strong></p>

<p><code>PROC UNIVARIATE DATA=SAS-data-set; <br>
    VAR variable(s); <br>
    ID variable_to_relate; <br>
    HISTOGRAM variables &lt;/options&gt;; <br>
    PROBPLOT variables &lt;/options&gt;; <br>
    INSET keywords &lt;/options&gt;; <br>
RUN;</code></p>

<ul>
<li>If you omit the <strong>VAR</strong> statement, all numeric variables in the data set are analyzed</li>
<li>The <strong>Extreme Observations</strong> table contains useful information to locate outliers: it displays the 5 lowest/highest values by default along with the corresponding observation number. The <strong>ID</strong> statement specifies that SAS will use this variable as a label in the table of extreme observations and as an identifier for any extreme.</li>
<li>To specify the number of listed observations you can use <strong>NEXTROBS=</strong></li>
<li><strong>HISTOGRAM/PROBPLOT</strong> options: normal(mu=est sigma=est) creates a normal curve overlay to the histogram using the estimates of the population mean and standard deviation</li>
<li><strong>INSET</strong> writes a legend for the graph. <code>/ position=ne</code> moves the <strong>INSET</strong> to the north-east corner of the graph.</li>
</ul>

<p>To include in the report only one of the automatically produced tables:</p>

<p>1) Check the specific table name in the <strong>LOG information</strong> using <strong>ODS TRACE</strong>:</p>

<p><code>ODS TRACE ON; <br>
PROC UNIVARIATE DATA=SAS-data-set; <br>
    VAR variable(s); <br>
RUN; <br>
ODS TRACE OFF;</code></p>

<p>2) Select the wanted table with <strong>ODS SELECT</strong>:</p>

<p><code>ODS SELECT ExtremeObs; <br>
PROC UNIVARIATE DATA=SAS-data-set; <br>
    VAR variable(s); <br>
RUN;</code></p>

<hr>

<p><strong><em>SUMMARY of validation procedures</em></strong></p>

<p><img src="validation_procedures.png" alt="alt text" title="Validation procedures"></p>



<h3 id="using-the-sas-output-delivery-system">Using the SAS Output Delivery System</h3>

<p><code>ODS destination FILE="filename" &lt;options&gt;; <br>
    &lt;SAS code to generate the report&gt; <br>
ODS destination CLOSE;</code></p>

<ul>
<li>You can have multiple destinations open and execute multiple procedures</li>
<li>All generated output will be sent to every open destination</li>
<li>You might not be able to view the file, or the most updated file, outside of SAS until you close the destination</li>
</ul>

<p><strong>E.g.:</strong></p>

<p><code>ODS pdf FILE="C:/output/test.pdf"; <br>
(...) <br>
ODS pdf CLOSE;</code></p>

<p><code>ODS csvall FILE="C:/output/test.cvs"; <br>
ODS rtf FILE="C:/output/test.rtf"; <br>
(...) <br>
ODS csvall CLOSE; <br>
ODS rtf CLOSE;</code></p>

<p><strong><em>Allowed file formats and their corresponding destinations:</em></strong> <br>
<img src="SAS_output_delivery_system.png" alt="alt text" title="SAS Output Delivery System"></p>



<h1 id="statistics">Statistics</h1>



<h2 id="introduction-to-statistics">Introduction to Statistics</h2>



<h3 id="basic-statistical-concepts">Basic Statistical Concepts</h3>

<ul>
<li><strong><em>Descriptive statistics (exploratory data analysis, EDA)</em></strong> <br>
<ul><li>Explore your data</li></ul></li>
<li><strong><em>Inferential statistics (explanatory modelling)</em></strong> <br>
<ul><li><strong>How is X related to Y?</strong></li>
<li>Sample sizes are typically small and include few variables</li>
<li>The focus is on the parameters of the model</li>
<li>To assess the model, you use p-values and confidence intervals</li></ul></li>
<li><strong><em>Predictive modelling</em></strong> <br>
<ul><li><strong>If you know X, can you predict Y?</strong></li>
<li>Sample sizes are large and include many predictive (input) variables</li>
<li>The focus is on the predictions of observations rather than the parameters of the model</li>
<li>To assess a predictive model, you validate predictions using holdout sample data</li></ul></li>
</ul>



<hr>

<p><strong>How to generate random (representative) samples (population subsets)</strong></p>

<p><code>PROC SURVEYSELECT DATA=SAS-data-set  <br>
                  OUT=name-of-output-data-set <br>
                  METHOD=method-of-random-sampling <br>
                  SEED=seed-value  <br>
                  SAMPSIZE=number-of-observations-desired; <br>
     &lt;STRATA stratification-variable(s);&gt; <br>
RUN;</code></p>

<ul>
<li><strong>METHOD</strong>: specifies the random sampling method to be used. For simple random sampling without replacement, use <strong>METHOD=SRS</strong>. For simple random sampling with replacement, use <strong>METHOD=URS</strong>. For other selection methods and details on sampling algorithms, see the SAS online documentation for PROC SURVEYSELECT.</li>
<li><strong>SEED</strong>: specifies the initial seed for random number generation. If no SEED option is specified, SAS uses the system time as its seed value. This creates a different random sample every time the procedure is run.</li>
<li><strong>SAMPSIZE</strong>: indicates the number of observations to be included in the sample. To select a certain fraction of the original data set rather than a given number of observations, use the <strong>SAMPRATE</strong> option.</li>
</ul>

<hr>

<ul>
<li><strong>Parameters</strong>: numerical values (typically unknown, you can’t measure the entire population) that summarize characteristics of a population (greek letters)</li>
<li><strong>Statistics</strong>: summarizes characteristics of a sample (standard alphabet)</li>
</ul>



<h2 id="you-use-statistics-to-estimate-parameters">* You use <strong>statistics</strong> to estimate <strong>parameters</strong></h2>

<ul>
<li><strong>Independent variable</strong>: it can take different values, it affects or determines a <strong>dependent variable</strong>. It can be called predictor, explanatory, control or input variable.</li>
</ul>



<h2 id="dependent-variable-it-can-take-different-values-in-response-to-an-independent-variable-also-known-as-response-outcome-or-target-variable">* <strong>Dependent variable</strong>: it can take different values in response to an <strong>independent variable</strong>. Also known as response, outcome or target variable.</h2>

<p><strong><em>Scale of measurement</em></strong>: variable’s classification <br>
<br>
* <strong>Quantitative/numerical variables</strong>: counts or measurements, you can perform arithmetical operations with it <br>
 * <strong>Discrete data</strong>: variables that can have only a countable number of values within a measurement range <br>
 * <strong>Continuous data</strong>: variables that are measured on a scale that has infinite number of values and has no breaks or jumps <br>
   * <strong>Interval scale data</strong>: it can be rank-ordered like ordinal data but also has a sensible spacing of observations such that differenes between measurements are meaningful but it lacks a true zero (ratios are meaningless) <br>
   * <strong>Ratio scale data</strong>: it is rank-ordered with meaningful spacing and also includes a true zero point and can therefore accurately indicate the ratio difference between two spaces on the measurement scale <br>
* <strong>Categorical/attribute variables</strong>: variables that denote groupings or labels <br>
 * <strong>Nominal data (qualitative/classification variable)</strong>: exhibits no ordering within its observed levels, groups or categories <br>
 * <strong>Ordinal data</strong>: the observed labels can be ordered in some meaningful way that implies that the differences between the groups or categories are due to magnitude</p>

<hr>

<ul>
<li><strong>Univariate analysis</strong> provides techniques for analyzing and describing a sigle variable. It reveals patterns in the data by looking at the <strong>range</strong> of values, measures of <strong>dispersion</strong>, the <strong>central tendecy</strong> of the values and <strong>frequency distribution</strong>.</li>
<li><strong>Bivariate analysis</strong> describes and explains the relationships between two variables and how they change or covary together. It include techniques such as <strong>correlation analysis</strong> and <strong>chi-square tests of independance</strong>.</li>
<li><strong>Multivariate/Multivariable analysis</strong> examines two or more variables at the same time in order to understand the relationships among them.  <br>
<ul><li>Techniques such as <strong>mutiple linear regression</strong> and n-way <strong>ANOVA</strong> are typically called <strong>multivariable</strong> analysis (only one response variable). </li>
<li>Techniques such as <strong>factora analysis</strong> and <strong>clustering</strong> are typically called <strong>mutivariate</strong> analysis (they consider more than one response variable).</li></ul></li>
</ul>



<h3 id="descriptive-statistics">Descriptive Statistics</h3>

<p><strong>Measures of central tendencies</strong>: mean (affected by outliers), median (less sensitive to outliers), mode</p>

<p>25th percentile = 1st/lower quartile = Q1<br>
50th percentile = median = middle quartile = Q2<br>
75th percentile = 3rd/upper quartile = Q3<br></p>

<p>The <strong>interquartile range (IQR)</strong> is the difference between Q1 and Q3, it is a <strong>robust estimate of the variability</strong> because changes in the upper/lower 25% of the data do not affect it. If there are <strong>outliers</strong> in the data, then the IQR is a more reliable measure of the spread than the overall range.</p>

<p>The <strong>coefficient of variation (CV)</strong> is a measure of the standard deviation expressed as a percentage of the mean (S/mean*100)</p>



<h3 id="picturing-your-data">Picturing Your Data</h3>

<p><strong>Normal distribution</strong>: (μ-σ,μ+σ) = 68%; (μ-2σ,μ+2σ) = 95%; (μ-3σ,μ+3σ) = 99%</p>

<p><em>How to check the normality of a sample?</em></p>

<ul>
<li>Compare the <strong>mean</strong> and the <strong>median</strong>: if they are nearly equal, that is an indicator of symmetry (requirement for normality).</li>
<li>Check that <strong>skewness</strong> and <strong>kurtosis</strong> are close to 0.</li>
</ul>

<p><strong><em>Statistical summaries:</em></strong> <strong>skewness</strong> and <strong>kurtosis</strong> measure certain aspects of the shape of a distribution (they are <strong>0</strong> and <strong>3</strong> for a normal distribution, although SAS has standardized both to 0) <br>
* <strong>Skewness</strong> measures the tendency of your data to be more spread out on one side of the mean than on the other (asymmetry of the distribution).  <br>
 * You can think of the direction of skewness as the direction the data is trailing off to.  <br>
 * A <strong>right-skewed</strong> distribution tells us that the mean is <strong>greater than the median</strong>. <br>
* <strong>Kurtosis</strong> measures the tendency of your data to be concentrated toward the center or toward the tails of the distribution (peakedness of the data, tail thickness).  <br>
 * A <strong>negative kurtosis (platykurtic distribution)</strong> means that the data has lighter tails than in a normal distribution.  <br>
 * A <strong>positive kurtosis (leptokurtic/heavy-tailed/outlier-prone distribution)</strong> means that the data has heavier tails and is more concentrated around the mean than a normal distribution. <br>
 * Rectangular, bimodal and multimodal distributions tend to have low values of kurtosis. <br>
 * <strong>Asymmetric distributions</strong> also tend to have nonzero kurtosis. In these cases, understanding kurtosis is considerably more complex and can be difficult to assess visually. <br>
* If <strong>skewness/kurtosis</strong>: <br>
 * Both are greater than 1 or less than -1: data is not normal</p>



<h2 id="either-is-greater-than-2-or-less-than-2-data-is-not-normal"> * Either is greater than 2 or less than -2: data is not normal</h2>

<p><strong><em>PLOTS PRODUCED WITH PROC UNIVARIATE</em></strong></p>

<ul>
<li><strong>Histograms</strong></li>
<li><strong>Normal probability plots</strong>: expected percentiles from standard normal vs actual data values</li>
</ul>

<p><img src="normalprobplots.png" alt="alt text" title="Normal Probability Plots"></p>

<p><strong><em>PLOTS PRODUCED WITH PROC SGSCATTER</em></strong></p>

<ul>
<li><strong>Scatter plots</strong>: you can create a <strong>single-cell</strong> (simple Y by X) scatter plot, a <strong>multi-cell</strong> scatter plot with multiple independent scatter plots in a grid and a <strong>scatter plot matrix</strong>, which produces a matrix of scatter plots comparing multiple variables.</li>
</ul>

<p><strong><em>PLOTS PRODUCED WITH PROC SGPLOT</em></strong></p>

<p><code>PROC SGPLOT DATA=SAS-data-set &lt;options&gt;; <br>
        DOT category-variable &lt;/options&gt;; <br>
        HBAR category-variable &lt;/options&gt;; <br>
        VBAR category-variable &lt;/options&gt;; <br>
        HBOX response-variable &lt;/options&gt;; <br>
        VBOX response-variable &lt;/options&gt;; <br>
        HISTOGRAM response-variable &lt;/options&gt;; <br>
        SCATTER X=variable Y=variable &lt;/options&gt;; <br>
        NEEDLE X=variable Y=numeric-variable &lt;/options&gt;; <br>
        REG X=numeric-variable Y=numeric-variable &lt;/options&gt;; <br>
RUN;</code></p>

<p>Anywhere in the procedure you can add <strong>reference lines</strong>:<br>
<code>REFLINE variable | value-1 &lt;... value-n&gt; &lt;/option(s)&gt;</code><br>
<strong>E.g.:</strong> <code>REFLINE 1200 / axis=y lineattrs=(color=blue);</code></p>

<ul>
<li><strong>Scatter plots (SCATTER)</strong></li>
<li><strong>Line graphs</strong></li>
<li><strong>Histograms (HISTOGRAM)</strong> with overlaid distribution curves</li>
<li><strong>Regression lines (REG)</strong> with confidence and prediction bands</li>
<li><strong>Dot plots (DOT)</strong></li>
<li><strong>Box plots (HBOX/VBOX)</strong>: it makes it easy to see how spread out your data is and if there are any outliers. The box represents the middle 50% of your data (IQR). The lower/middle/upper <strong>line of the box</strong> represent Q1/Q2/Q3. The <strong>diamond</strong> denotes the mean (easy to check how close the mean is to the median). The <strong>whiskers</strong> extend as far as the data extends to a maximum length of 1.5 times the IQR above Q3. Any data points farther than this distance are considered possible outliers and are represented in this plot as <strong>circles</strong>.</li>
<li><strong>Bar charts (HBAR/VBAR)</strong></li>
<li><strong>Needle plot (NEEDLE)</strong>: creates a plot with needles connecting each point to the baseline</li>
<li>You can also <strong>overlay plots together</strong> to produce many different types of graphs</li>
</ul>

<p><strong><em>PLOTS PRODUCED WITH PROC SGPANEL</em></strong></p>

<ul>
<li><strong>Panels of plots</strong> for different levels of a factor or several different time periods depending on the classification variable</li>
<li><strong>Side-by-side histograms</strong> which provide a visual comparison for your data</li>
</ul>

<p><strong><em>PLOTS PRODUCED WITH PROC SGRENDER</em></strong></p>

<ul>
<li><strong>Plots from graphs templates you have modified or written yourself</strong></li>
</ul>

<hr>

<p>To specify options for graphs you submit the <strong>ODS GRAPHICS</strong> statement:<br>
<code>ODS GRAPHICS ON &lt;options&gt;;</code></p>

<ul>
<li>To select/exclude specific test results, graphs or tables from you output, you can use <strong>ODS SELECT</strong> and <strong>ODS EXCLUDE</strong> statements.</li>
<li>You can use ODS templates to modify the layout and details of each graph</li>
<li>You can use ODS styles to control the general appearance and consistency of yous graphs and tables (by default <strong>HTMLBLUE</strong>).</li>
</ul>

<p>Another way to control you output is to use the <strong>PLOT</strong> option which is usually available in the procedure statement:<br>
<code>PROC UNIVARIATE DATA=SAS-data-set PLOTS=options;</code><br>
This option enables you to specify which graphs SAS should create, either in addtion or instead of the default plots.</p>



<h3 id="confidence-intervals-for-the-mean">Confidence Intervals for the Mean</h3>

<ul>
<li>A <strong>point estimator</strong> is a sample statistic used to estimate a population parameter</li>
<li>An estimator takes on different values from sample to sample, so it’s important to know its variance</li>
<li>A statistic that measures the variability of your estimator is the <strong>standard error</strong></li>
<li>It differs from the standard deviation: the <strong>standard deviation</strong> deals with the variability of your data while <strong>standard error</strong> deals with the variability of you sample statistic</li>
</ul>

<p><strong>E.g.:</strong> Standard error of the mean = standard deviation/sqrt(sample size)</p>

<p>The <strong>distribution of sample means</strong> is always less variable than the data.</p>

<ul>
<li>Because we know that point estimators vary from sample to sample, it would be nice to have an estimator of the mean that directly accounts for this natural variability</li>
<li>The <strong>interval estimator</strong> gives us a range of values that is likely to contain the population mean</li>
<li>It is calculated from the <strong>standard error</strong> and a value that is determined by the <strong>degree of certainty</strong> we require (<strong>significance level</strong>)</li>
<li><strong>Confidence intervals</strong> are a type of interval estimator used to estimate the population mean</li>
<li>You can make the confidence interval narrower by increasing the sample size and by decreasing the confidence level</li>
</ul>

<p>CI = sample mean ± quantile * standard error</p>

<ul>
<li>The <strong>CLM</strong> option of <strong>PROC MEANS</strong> calculates the confidence limits for the mean, you can add <strong>alpha=</strong> to change the default 0.05 value for a 95% confidence level</li>
<li>The <strong>central limit theorem</strong> states that the distribution of sample means is approximately normal regardless of the population distribution’s shape, if the sample size is large enough (~30 observations)</li>
</ul>



<h3 id="hypothesis-testing">Hypothesis Testing</h3>

<ul>
<li>The <strong>null hypothesis (H0)</strong> is what you assume to be true when you start your analysis</li>
<li>The <strong>alternative hypothesis (Ha/H1)</strong> is your initial research hypothesis, that is, your proposed explanation</li>
</ul>

<p>Decision-making process: <br>
1. Define null and alternative hypothesis <br>
2. Specify significance level (type I error rate) <br>
3. Collect data <br>
4. Reject or fail to reject the null hypothesis</p>

<p><img src="errortype.PNG" alt="alt text" title="Error types"></p>

<ul>
<li>The type I and II errors are <strong>inversely related</strong>: as one type increases the other decreases </li>
<li><p>The <strong>power</strong> is the probability of a <strong>correct rejection</strong> = 1 - β</p>

<ul><li>It is the ability of the statistical test to detect a true difference</li>
<li>It is the ability to successfully reject a false null hypothesis</li></ul></li>
<li><p>A <strong>p-value</strong> measures the probability of observing a value as extreme as the one observed</p>

<ul><li>The p-value is used to determine <strong>statistical significance</strong></li>
<li>It helps you assess whether you should reject the null hypothesis</li></ul></li>
<li><p>The <strong>p-value</strong> is affected by:</p>

<ul><li>The <strong>effect size</strong>: the difference between the observed statistic and the hypothesized value</li>
<li>The <strong>sample size</strong>: the larger the sample size, the more sure you are about the sample statistics, the lower the p-value is</li></ul></li>
<li><p>A reference distribution enables you to quantify the probability (p-value) of observing a particular outcome (the calculated sample statistic) or a more extreme outcome, if the nul hypothesis is true</p></li>
<li>Two common reference distributions for statistical hypothesis testing are the <strong>t distribution</strong> and the <strong>F distribution</strong></li>
<li>These distributions are characterized by the <strong>degrees of freedom</strong> associated with your data</li>
<li>The <strong>t distribution</strong> arises when you’re making inferences about a population mean and the population standard deviation is unknown and has to be estimated from the data <br>
<ul><li>It is <strong>approximately normal</strong> as the <strong>sample size grows larger</strong></li>
<li>The t distribution is a <strong>symmetric distribution</strong> like the normal distribution except that the t distribution has <strong>thicker tails</strong></li>
<li>The <strong>t statistic</strong> is positive/negative when the sample is more/less than the hypothesized mean</li>
<li>If the data doesn’t come from a normal distribution, then the t statistic approximately follows a t distribution as long as the sample size is large (<strong>central limit theorem</strong>)</li></ul></li>
</ul>

<p>Calculation with <strong>PROC UNIVARIATE</strong>:</p>

<p><code>ODS SELECT TESTSFORLOCATION; <br>
PROC UNIVARIATE DATA=SAS-data-set MU0=number alpha=number; <br>
    VAR variable(s); <br>
    ID variable_to_relate; <br>
    HISTOGRAM variables &lt;/options&gt;; <br>
    PROBPLOT variables &lt;/options&gt;; <br>
    INSET keywords &lt;/options&gt;; <br>
RUN;</code></p>

<ul>
<li><strong>TESTSFORLOCATION</strong> displays only the p-values calculation</li>
<li>By default <strong>MU0 = 0</strong></li>
</ul>



<h2 id="analysis-of-variance-anova">Analysis of Variance (ANOVA)</h2>

<p><img src="https://lh3.googleusercontent.com/-rATf9P-cqCY/WMu2osKuCrI/AAAAAAAAaho/zpN2p03U8o0jwAv-sZZPZSibuhvaRDWvQCLcB/s0/anova.png" alt="alt text" title="ANOVA"></p>



<h3 id="graphical-analysis-of-associations">Graphical Analysis of Associations</h3>

<ul>
<li>Before analyzing your data, you need to have a general idea of any associations between <strong>predictor variables</strong> and <strong>response variables</strong></li>
<li>An <strong>association</strong> exists between two variables when the expected value of one variable differs at different levels of the other variable</li>
<li>One method for doing this is to conduct a <strong>graphical analysis</strong> of your data</li>
<li>Associations between <strong>categorical</strong> predictor variable and a <strong>continuous</strong> response variable can be explored with <strong>SGPLOT</strong> to product <strong>box plots (box-and-whisker plots)</strong> (<strong>X</strong> predictor variable vs <strong>Y</strong> response variable)</li>
<li>If the <strong>regression line</strong> conecting the means of Y at each value of X is not horizontal <strong>there might be an association</strong> between them</li>
<li>If the <strong>regression line</strong> is horizontal <strong>there is no association</strong>: knowing the value of X doesn’t tell you anything about the value of Y</li>
</ul>

<p><code>PROC SGPLOT DATA=SAS-data-set; <br>
        VBOX response-variable / CATEGORY=predictor-variable CONNECT=MEAN; <br>
RUN;</code></p>



<h3 id="two-sample-t-tests">Two-Sample t-Tests</h3>

<ul>
<li>You can use a <strong>one-sample t-test</strong> to determine if the mean of a population is equal to a particular value or not</li>
<li>When youc ollect a random sample of independent observations from two differen populations, you can perform a <strong>two-sample t-test</strong></li>
</ul>

<p>When you compare the means of two populations using a <strong>two-sample t-test</strong> you make three assumptions:</p>

<ul>
<li>The data contains independent observations</li>
<li>The distributions of the two populations are normal </li>
<li>The variances in these normal distributions are equal</li>
</ul>



<h3 id="one-way-anova">One-Way ANOVA</h3>



<h3 id="anova-with-data-from-a-randomized-block-design">ANOVA with Data from a Randomized Block Design</h3>



<h3 id="anova-post-hoc-tests">ANOVA Post Hoc Tests</h3>



<h3 id="two-way-anova-with-interactions">Two-Way ANOVA with Interactions</h3>



<h1 id="macros">Macros</h1>

<p>You can learn about macros in the <strong>SAS Macro Language 1: Essentials course</strong>.</p>



<h3 id="macro-program-for-creating-box-plots-for-all-of-predictor-variables">Macro Program for Creating Box Plots for All of Predictor Variables</h3>

<p><code>%let categorical=House_Style2 Overall_Qual2 Overall_Cond2 Fireplaces  <br>
         Season_Sold Garage_Type_2 Foundation_2 Heating_QC  <br>
         Masonry_Veneer Lot_Shape_2 Central_Air; <br>
/* Macro Usage: %box(DSN = , Response = , CharVar = ) */ <br>
%macro box(dsn      = , <br>
           response = , <br>
           Charvar  = ); <br>
%let i = 1 ; <br>
%do %while(%scan(&amp;charvar,&amp;i,%str( )) ^= %str()) ; <br>
    %let var = %scan(&amp;charvar,&amp;i,%str( )); <br>
    proc sgplot data=&amp;dsn; <br>
        vbox &amp;response / category=&amp;var  <br>
                         grouporder=ascending  <br>
                         connect=mean; <br>
        title "&amp;response across Levels of &amp;var"; <br>
    run; <br>
    %let i = %eval(&amp;i + 1 ) ; <br>
%end ; <br>
%mend box; <br>
%box(dsn      = statdata.ameshousing3, <br>
     response = SalePrice, <br>
     charvar  = &amp;categorical); <br>
title; <br>
options label;</code></p>